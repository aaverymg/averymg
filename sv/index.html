<!DOCTYPE html>
<html>

<head>
    <title>sound & vision final</title>
    <link rel="stylesheet" href="css\style.css">
    <script src="https://unpkg.com/hydra-synth"></script>

    <script src="https://code.jquery.com/jquery-3.6.0.js"
        integrity="sha256-H+K7U5CnXl1h5ywQfKtSj8PCmoN9aaq30gDh27Xc0jk=" crossorigin="anonymous"></script>
    <script src="js/interaction.js" type="text/javascript"></script>
</head>

<body>
    <div class="hydra">
        <canvas id="hydraCanvas"></canvas>

        <script>
            var hydra = new Hydra({
                canvas: document.getElementById("hydraCanvas"),
                detectAudio: false
            });

            speed = .045
            osc()
                .modulateKaleid(osc(2))
                .modulate(noise(6))
                .diff(solid(.3, .5, .6))
                .brightness(.6)
                .scale(2)
                .out(o0)

        </script>
    </div>

    <div class="header" id="top">
        <h1>SOUND & VISION</h1>
        <h3>avery murray-gurney</h3>
        <hr>
        <h2>computer voices:</h2>
        <h2>a gender exploration</h2>

    </div>
    <br>
    <div class="main">
        <h2>What is a voice? What purpose does it serve? What is it supposed to sound like?</h2>
        <p>Steven Connor’s “What I Say Goes” describes the voice as “not a condition, nor yet an attribute, but an
            event” <i>(Connor, 4)</i>. Mladen Dolar further posits that “The voice is the instrument, the vehicle, the
            medium, and the meaning is the goal” <i>(Dolar, 15)</i>. The voice is used to express one’s thoughts, and to
            externalize their internal ideas. Through the voice, people are able to connect and share themselves with
            one another. As Pettman states, “Speaking “face-to-face” is a model of intimacy” <i>(Pettman, 3)</i>. The
            voice is a deeply personal aspect of one’s self; Connor compares it to other distinct human traits like
            fingerprints, hair color, or eye color, but notes that the voice differs from other traits because it must
            be actively and intentionally produced. <b>The voice is shared on purpose; the self is expressed
                intentionally.</b>
            But what happens to these conceptions of self when the voice is modified? What if it’s synthesized entirely
            by something non-human? Voice synthesis and digital modulation have created new kinds of voices and new
            forms for the voice to take. This raises the question: do these voices function the same way as unmodified
            ones? Do they facilitate the same forms of connection and expression? Are these still human voices?
        </p> <br>
        <p>Synthetic voice technology has existed <a
                href="https://en.wikipedia.org/wiki/Wolfgang_von_Kempelen%27s_speaking_machine" target="_blank">in some
                form since the 1770’s</a>, predating the invention of technologies
            like synthesizers entirely. In the last 250 years, this technology has evolved significantly and been
            applied widely. Computerized voices are used today to give voice to programs for a wide variety of purposes,
            including as an accessibility tool (ex: text-to-speech), for creative expression (ex: autotune), and for
            convenience when interacting with technology (ex: voice activation). The category of “computer voice”
            includes both entirely digitally synthesized voices, as well as regular human speech being modified by
            computer technology.</p>
        <br>
        <p>Computer voices fill the interesting role of being simultaneously human and inhuman in nature. They speak in
            human language, and are often created out of actual human speech, yet they’re still distinctly and
            identifiably computerized. As “The Linguistics of the Voice” states, “The <b>impersonal voice, the
                mechanically
                produced voice</b> (answering machines, computer voices, and so on) always has a touch of the uncanny…
            The voice
            without side-effects ceases to be a “normal” voice, it is deprived of the human touch that the voice adds to
            the arid machinery of the signifier, threatening that humanity itself will merge with the mechanical
            iterability, and thus lose its footing” <i>(Dolar, 22)</i>. The computerized voice seems inhuman because it
            is too perfect, lacking the usual anomalies of human speech. We can recognize these voices as human in
            origin, but not in output. The computer voice can still express human ideas, but they often lose their
            personal and emotional impact. There are many aspects to a voice, and computers can only recreate some of
            them. The associated sense of personality and identity is often lost in translation.</p>
        <br>
        <p>The voice is an element of identity and self expression, and one critical aspect of this is the role that the
            voice plays in gender presentation. The voice is, among many other things, a gender signifier; whether
            people are aware of it or not, when they listen to someone talking, they decide whether it’s masculine or
            feminine based on a complicated system of indicators. These indicators include aspects like pitch, but also
            intonation, mannerisms, resonance, and a variety of other elements beyond just how the voice sounds. The
            gendering of a voice often also relies on visual indicators, further complicating this process. This entire
            process typically happens almost completely subconsciously. When this act of gendering becomes a conscious
            process, it becomes much more difficult. Reflecting on what makes a voice sound “feminine” versus
            “masculine” makes it increasingly difficult to tell the difference; surface level assumptions, like the
            belief that feminine voices are always higher pitched, are often much more complicated in reality. As you
            begin to pay attention to your assumptions about how a voice is gendered, compared to what actual human
            voices sound like, it becomes increasingly clear that they often don’t fully align. Eventually, you begin to
            lose all sense of what a gendered voice sounds like. This is especially true when hearing a voice without
            seeing the associated body. Without having visual indicators of gender to refer to, auditory indicators
            become even less clear.
        </p><br>
        <p>If vocal gender is much more complicated and less defined than one might initially assume, and relies heavily
            on other indicators beyond just the intrinsic sound qualities of a voice, then this prompts the question:
            can computer voices be gendered? Many of these indicators are not qualities that a computer voice typically
            recreates. For example, there’s generally no associated genderable body, and factors like speech mannerisms
            are often irrelevant to computer voices. As Connor states, "Modern acoustic technologies, which allow the
            transmission, reception, and multiplication of voices at a distance, produce new configurations of the
            imaginary space of
            the body and the socio-cultural spaces of its utterance. Once again, the body is not located so much as
            distributed in space" <i>(Connor, 13)</i>. By mechanically altering the voice, we also mechanically alter
            the perception of the body. In theory, the voice and the body are interconnected, inseparable from one
            another. <mark>And yet, computer voices get gendered all of the time,
                whether it
                be intentionally through their marketing (ex: personal assistant programs like Siri and Alexa), or
                through a
                less explicit association.</mark> <br><br>
            <audio controls>
                <source src="media\tts.mp3" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio><br>
            <sub>(see? this isn't even a human voice, but it's somehow still a woman's voice)</sub>
            <br>
            <br>
            When these factors are present, it’s typically because the computer is voicing
            something that a human wrote, and is representing the traits and mannerisms of that human. Dolar describes
            computer voices as “impersonal”. But is this still the case when a human is telling the computer how to
            speak? Or is providing the instructions on how to modify the voice? Or in cases in which the computer is
            speaking in place of a person who cannot speak? (Ex: someone like <a
                href="https://www.youtube.com/watch?v=wn_G22hShGY" target="_blank">Stephen Hawking</a>) <b>Are these
                voices
                always
                inherently impersonal because the sound waves are coming from a digital source? Or is it possible to use
                the
                modulated, computerized voice for further self expression?</b>
        </p>
        <br>
        <p>What comes to mind is the way in which autotuning has been used by many vocal performers to establish a
            distinct sonic identity within their work. In particular, many transgender vocalists use very exaggerated
            autotune to create a new voice. These highly digitized voices don’t sound particularly natural or human, but
            they do still sound deeply distinct and personal.
        </p><br>
        <p>A prominent example of this is musician <a href="https://soundcloud.com/osno1" target="_blank">Laura Les</a>,
            best known for her work with the band 100 gecs. Les is a transgender woman who has become known for her
            distinct heavily autotuned voice.
            <br><br>
            <audio controls>
                <source src="media\laurales2.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio><br>
            <sub>(<a href="https://www.youtube.com/watch?v=fQAjveYLtHQ" target="_blank">original song</a> - this audio
                is just the vocals)</sub>
            <br>
            <br>
            Journalist Dylan Burgoon describes her reputation, stating that “In this
            case, Laura Les’ trans identity plays a significant role in the aesthetic choice of distorted vocals, and
            she has often explained that she uses pitch correction and autotune to alleviate the dysphoria produced by
            the tone of her unaltered singing voice”. <a href="https://www.youtube.com/watch?v=q1iIyorYLxw"
                target="_blank">Even when performing live, Les uses live autotuning technology to achieve her
                recognizably digitized voice.</a> In this example, computer technology is used to create a voice that’s
            a more authentic expression of the self, rather than an “impersonal” mechanical voice. <b>The voice that
                listeners hear in her music is simultaneously her voice and not her voice, both her voice and the voice
                of a
                machine.</b> This form of affirming gender expression becomes possible only through the use of a
            computer voice. As described in "What I Say Goes", "From being a source of powerfully mingled pleasure and
            menace, the technologically autonomized voice becomes a source simply of repeatable pleasure, or of the
            pleasure of repeatability itself… The technologies of the voice are actualizations of fantasies and desires
            concerning the voice which predate the actual technologies"<i>(Connor, 40)</i>. The ability to
            technologically modify the voice has been a source of a lot of anxiety for some people, but for many, it's
            also a source of euphoria.
            For people like Les, the computer voice actually allows for further and more authentic connection with a
            community and an audience. Her synthesized voice allows her to reach the people she’s trying to reach and to
            express the emotions that she’s trying to express by removing communication barriers created by voice
            dysphoria.
        </p><br>
        <p>Musicians like Laura Les using a synthetic computer voice to create more earnest self expression challenges
            notions around what the human voice is supposed to sound like, what the human voice is capable of sounding
            like, and how we define what an individual’s voice sounds like. <b>Is this version of a machine voice still
                “impersonal”?</b> If Les finds a more authentic voice through a machine, then what separates her
            synthesized
            voice from her “real” voice? What makes a voice real? What makes a voice human? </p>
        <br>
        <p>The computer voice is simultaneously removed from the context of gender, but also paradoxically used to
            further express gender. When removed from the context of an individual, the computer voice loses all sense
            of gender, but when designed and utilized by an individual, the computer voice becomes an expression of
            gender. Through this contradiction, we can better understand the functions of the human voice, as well as
            the merits and complications associated with the gendering of the voice. If the voice can be gendered, it’s
            because it’s expressing human traits, and is recreating the gender indicators of the person instructing the
            computer (or creating the program, etc). This means that the computer voice cannot be separated from the
            human qualities that it inherets from the people that created it. <b>At its very core, the computer voice is
                human.</b></p>
    </div>
    <br>
    <div class="biblio">
        <ul id="sources">
            <li><a href="http://research.spa.aalto.fi/publications/theses/lemmetty_mst/chap2.html" target="_blank">Aalto
                    University, "History and Development of Speech Synthesis".</a></li>
            <li><a href="https://avidly.lareviewofbooks.org/2021/01/14/notes-on-100-gecs/" target="_blank">Burgoon,
                    Dylan. "Notes on 100 Gecs", Avidly.</a></li>
            <li>Connor, Steven. "What I Say Goes"</li>
            <li>Dolar, Mladen. "The Linguistics of the Voice"</li>
            <li><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00023/full" target="_blank">Pernet,
                    Cyril and Belin, Pascal. "The role of pitch and timbre in voice gender categorization", Frontiers in
                    Psychology.</a></li>
            <li>Pettman, Dominic. "Sonic Intimacy"</li>
        </ul>
        <button id="toggle">SHOW SOURCES</button>
        <button><a href="#top">RETURN TO TOP</a></button>
        <button><a href="https://github.com/aaverymg/averymg/tree/main/sv" target="_blank">GITHUB REPO</a></button>
    </div>
    <br><br>
</body>

</html>